{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pyzbar.pyzbar import decode\n",
    "\n",
    "qcd = cv2.QRCodeDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen_image(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Blur the image to remove noise\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Perform unsharp masking\n",
    "    unsharp_mask = cv2.addWeighted(gray, 1.5, blur, -0.5, 0)\n",
    "\n",
    "    return unsharp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the image\n",
    "image = cv2.imread(\"TestImg/real_test_.jpg\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imwrite(\"contour/gray.jpg\", gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the image\n",
    "ret, threshold = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "cv2.imwrite(\"contour/threshold.jpg\", gray)\n",
    "\n",
    "# Find the contours of the QR codes\n",
    "contours, hierarchy = cv2.findContours(threshold, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "len(contours)\n",
    "\n",
    "decoded_data = decode(threshold)\n",
    "if decoded_data:\n",
    "    # cv2.imwrite(\"contour/contour_\" + str(qrCount) + \".jpg\", qr_code_image)\n",
    "    # print(retval,decoded_info)\n",
    "    for qrCode in decoded_data:\n",
    "        print(qrCode.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2410\n"
     ]
    }
   ],
   "source": [
    "qrCount = 0\n",
    "\n",
    "for cnt in contours:\n",
    "    # Check if the contour is convex\n",
    "    if cv2.isContourConvex(cnt):\n",
    "        \n",
    "        # Get the bounding rectangle of the QR code\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # print(w,h)\n",
    "        \n",
    "        # Extract the QR code from the image\n",
    "        qr_code_image = threshold[y:y+h, x:x+w]\n",
    "        \n",
    "        # qr_code_image = sharpen_image(qr_code_image)\n",
    "        \n",
    "        # Use a QR code library to decode the QR code and get the encoded information\n",
    "        # retval, decoded_info, points, straight_qrcode = qcd.detectAndDecodeMulti(qr_code_image)\n",
    "        # print(qr_code_image)\n",
    "        # cv2.imwrite(\"contour/contour_\" + str(qrCount) + \".jpg\", qr_code_image)\n",
    "        qrCount += 1\n",
    "        \n",
    "        if( w >= 20 and h >= 20 ):\n",
    "            decoded_data = decode(qr_code_image)\n",
    "            cv2.imwrite(\"contour/contour_\" + str(qrCount) + \".jpg\", qr_code_image)\n",
    "        \n",
    "            if decoded_data:\n",
    "                # cv2.imwrite(\"contour/contour_\" + str(qrCount) + \".jpg\", qr_code_image)\n",
    "                print(1)\n",
    "                # print(retval,decoded_info)\n",
    "                for qrCode in decoded_data:\n",
    "                    print(qrCode.data)\n",
    "            \n",
    "            \n",
    "print(qrCount)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('contour/2.jpg')\n",
    "\n",
    "# img = sharpen_image(img)\n",
    "# cv2.imwrite(\"contour/contour_\" + str(qrCount) + \".jpg\", qr_code_image)\n",
    "\n",
    "qcd = cv2.QRCodeDetector()\n",
    "retval, decoded_info, points, straight_qrcode = qcd.detectAndDecodeMulti(img)\n",
    "\n",
    "retval\n",
    "decoded_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "\n",
    "# Read the QR code from an image file\n",
    "decoded_data = decode(img)\n",
    "\n",
    "decoded_data\n",
    "# Print the decoded QR code data\n",
    "# print(decoded_data[0].data.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_box(image, kp):\n",
    "    # Get the coordinates of the keypoints\n",
    "    coords = np.array([kp[i].pt for i in range(len(kp))])\n",
    "\n",
    "    # Get the bounding rectangle of the keypoints\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "\n",
    "    # Crop the image using the bounding rectangle coordinates\n",
    "    crop_img = image[y:y+h, x:x+w]\n",
    "\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2320\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\shapedescr.cpp:874: error: (-215:Assertion failed) npoints >= 0 && (depth == CV_32F || depth == CV_32S) in function 'cv::pointSetBoundingRect'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(kp))\n\u001b[0;32m     10\u001b[0m     boxes \u001b[39m=\u001b[39m crop_box(img,kp)\n\u001b[1;32m---> 12\u001b[0m detect_boxes(cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39mTestImg/zz.png\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "Cell \u001b[1;32mIn [14], line 10\u001b[0m, in \u001b[0;36mdetect_boxes\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m# cv2.imshow(\"Keypoints\", img)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# cv2.waitKey(0)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# cv2.destroyAllWindows()\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(kp))\n\u001b[1;32m---> 10\u001b[0m boxes \u001b[39m=\u001b[39m crop_box(img,kp)\n",
      "Cell \u001b[1;32mIn [13], line 6\u001b[0m, in \u001b[0;36mcrop_box\u001b[1;34m(image, kp)\u001b[0m\n\u001b[0;32m      3\u001b[0m coords \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([kp[i]\u001b[39m.\u001b[39mpt \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(kp))])\n\u001b[0;32m      5\u001b[0m \u001b[39m# Get the bounding rectangle of the keypoints\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m x, y, w, h \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mboundingRect(coords)\n\u001b[0;32m      8\u001b[0m \u001b[39m# Crop the image using the bounding rectangle coordinates\u001b[39;00m\n\u001b[0;32m      9\u001b[0m crop_img \u001b[39m=\u001b[39m image[y:y\u001b[39m+\u001b[39mh, x:x\u001b[39m+\u001b[39mw]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\shapedescr.cpp:874: error: (-215:Assertion failed) npoints >= 0 && (depth == CV_32F || depth == CV_32S) in function 'cv::pointSetBoundingRect'\n"
     ]
    }
   ],
   "source": [
    "def detect_boxes(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(gray, None)\n",
    "    img = cv2.drawKeypoints(gray, kp, None)\n",
    "    # cv2.imshow(\"Keypoints\", img)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    print(len(kp))\n",
    "    boxes = crop_box(img,kp)\n",
    "    \n",
    "detect_boxes(cv2.imread(\"TestImg/zz.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
